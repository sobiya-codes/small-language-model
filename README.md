# Small Language Model (SLM) from Scratch ğŸ‘©â€ğŸ’»

![Project Demo](assets/demo.gif)  

A **Small Language Model (SLM)** trained on [TinyStories](https://huggingface.co/datasets/roneneldan/TinyStories) dataset to generate creative and coherent text.  
This project is implemented from scratch in **PyTorch**, inspired by the work of **Vizuara AI Labs**.  

---

## ğŸŒŸ Features

- Small-scale GPT-like architecture (~50-60M parameters)  
- Trained on TinyStories dataset (kid-friendly short stories)  
- Causal self-attention for next-token prediction  
- Mixed precision training for faster computation  
- Generate text given a prompt with controllable length and randomness  

---

## ğŸ“‚ Project Structure

small-language-model/
â”œâ”€â”€ assets/
â”‚ â””â”€â”€ demo.gif # Project demo GIF
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ train.bin
â”‚ â””â”€â”€ validation.bin
â”œâ”€â”€ saved_models/
â”‚ â””â”€â”€ best_model_params.pt # Trained model weights
â”œâ”€â”€ data_preparation.py # Tokenize dataset and create .bin files
â”œâ”€â”€ train.py # Model training code
â”œâ”€â”€ inference.py # Run inference / generate text
â”œâ”€â”€ requirements.txt # Python dependencies
â””â”€â”€ README.md # Project documentation
